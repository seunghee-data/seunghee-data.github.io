---
title: "[파이썬 깊게 파기] Day 9: 전처리, 머신러닝 성패의 80%를 결정하는 정제술"
date: 2026-01-11
categories: [python]
layout: single
author_profile: true
header:
  overlay_image: "/assets/images/python-10days/day1/Mbanner.png"
---

## 1. 오늘의 목표
"쓰레기를 넣으면 쓰레기가 나온다(GIGO)." 더러운 데이터를 정제하고 기계가 학습하기 좋은 규격으로 맞추는 **Preprocessing**의 전략적 가치를 분석합니다.

---

## 2. 오염된 데이터 정제 전략

### 1) 전처리: `Preprocessing`
* **어원:** **Pre**(미리) + **Processing**(가공).
* **심층 분석:** 요리 전 재료를 손질하듯, 학습(Process) 전에 데이터의 **노이즈를 제거**하고 수치적 범위를 맞추는 모든 공정입니다.

### 2) 결측치 처리: `NaN` (Not a Number)
* **전략 분석:** 비어있는 데이터(NaN)를 무조건 삭제하면 정보 손실이 큽니다. 데이터 성격에 따라 **평균/중앙값으로 보간(Impute)**하거나, 최빈값으로 채우는 전략적 선택이 모델의 정밀도를 결정합니다.

---

## 3. 수치의 정규화: 스케일링(Scaling)
* **심층 분석:** 단위가 다른 데이터(예: 수입 1억 vs 나이 30세)를 동일한 저울 위에 올리는 과정입니다. 표준화(Standardization)를 통해 숫자의 크기 차이로 인한 왜곡을 방지합니다.

---

## 4. 실습 코드 (전처리 전략 주석)

```python
import pandas as pd
import numpy as np

# 1. 결측치 포함 데이터
df = pd.DataFrame({'Val': [10, 20, np.nan, 40]})

# 2. 보간(Imputation) 전략: 평균으로 채우기
df['Val'] = df['Val'].fillna(df['Val'].mean())

# 3. 데이터 분포 확인
print(df.describe())
```

---

## 🧭 오늘의 핵심 분석 및 요약
1. **Preprocessing** = 모델 성능을 좌우하는 데이터 엔지니어링의 본체
2. **NaN Strategy** = 삭제(Deletion)와 보간(Imputation) 사이의 기회비용을 계산해야 함
3. **Feature Scaling** = 데이터의 가중치 왜곡을 막기 위한 필수적인 정규화 단계
4. **Clean Data** = 잘 정제된 데이터는 단순한 모델로도 최상의 성능을 낼 수 있게 함
